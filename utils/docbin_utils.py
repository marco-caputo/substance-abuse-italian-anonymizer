import spacy
from spacy.tokens import DocBin
from spacy.util import filter_spans

from utils.json_utils import read_json_file, to_spacy_format


def load_data_for_spacy(file_path: str):
    """Loads training data from a JSON file in the format generated by data_generation module and converts it to spaCy format."""
    data = read_json_file(file_path)
    return to_spacy_format(data)


def to_docbin_format(data, permitted_labels: set[str] = None) -> DocBin:
    """Converts training data in the spaCy format into spaCy's DocBin format."""
    nlp = spacy.load("it_core_news_lg")
    doc_bin = DocBin()

    for item in data:
        text = item[0]
        labels = item[1]['entities']
        doc = nlp.make_doc(text)
        ents = []
        for start, end, label in labels:
            span = doc.char_span(start, end, label=label, alignment_mode="expand")
            if span is None:
                print(f"Skipping entity [{text[start:end]}] in text [{text[:min(100,len(text))]}...] due to misalignment.")
            elif permitted_labels and label not in permitted_labels:
                continue
            else:
                ents.append(span)
        filtered_ents = filter_spans(ents)
        doc.ents = filtered_ents
        doc_bin.add(doc)

    return doc_bin


def load_docbin(file_path: str) -> DocBin:
    """Loads a DocBin object from a .spacy file."""
    doc_bin = DocBin().from_disk(file_path)
    return doc_bin


def combine_docbins(docbins: list[DocBin]) -> DocBin:
    """Combines multiple DocBin objects into one."""
    combined_docbin = DocBin()
    for db in docbins:
        for doc in db.get_docs(spacy.blank('it').vocab):
            combined_docbin.add(doc)
    return combined_docbin